# OpenAI GPT models
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_open_ai_api_key

# GitHub Models (OpenAI models hosted by GitHub)
# Get your Personal Access Token from: https://github.com/settings/tokens
# - Select "Fine-grained tokens" 
# - Set repository access to "All repositories" 
# - Enable "GitHub Models" permission
GITHUB_API_KEY=github_pat_your_personal_access_token_here

# ======================================
# CUSTOM PROVIDER BASE URLS (Optional)
# ======================================

# Ollama (Local models)
# DON'T USE http://localhost:11434 due to IPv6 issues
# USE: http://127.0.0.1:11434
OLLAMA_API_BASE_URL=http://127.0.0.1:11434

# OpenAI-like API (Compatible providers)
OPENAI_LIKE_API_BASE_URL=your_openai_like_base_url_here
OPENAI_LIKE_API_KEY=your_openai_like_api_key_here

# Together AI Base URL
TOGETHER_API_BASE_URL=your_together_base_url_here

# Hyperbolic Base URL
HYPERBOLIC_API_BASE_URL=https://api.hyperbolic.xyz/v1/chat/completions

# LMStudio (Local models)
# Make sure to enable CORS in LMStudio
# DON'T USE http://localhost:1234 due to IPv6 issues
# USE: http://127.0.0.1:1234
LMSTUDIO_API_BASE_URL=http://127.0.0.1:1234

# ======================================
# CLOUD SERVICES CONFIGURATION
# ======================================

# AWS Bedrock Configuration (JSON format)
# Get your credentials from: https://console.aws.amazon.com/iam/home
# Example: {"region": "us-east-1", "accessKeyId": "yourAccessKeyId", "secretAccessKey": "yourSecretAccessKey"}
AWS_BEDROCK_CONFIG=your_aws_bedrock_config_json_here

# ======================================
# GITHUB INTEGRATION
# ======================================

# GitHub Personal Access Token
# Get from: https://github.com/settings/tokens
# Used for importing/cloning repositories and accessing private repos
VITE_GITHUB_ACCESS_TOKEN=your_github_personal_access_token_here

# GitHub Token Type ('classic' or 'fine-grained')
VITE_GITHUB_TOKEN_TYPE=classic

# ======================================
# DEVELOPMENT SETTINGS
# ======================================

# Development Mode
NODE_ENV=development

# Application Port (optional, defaults to 3000)
PORT=3000

# Logging Level (debug, info, warn, error)
VITE_LOG_LEVEL=debug

# Default Context Window Size (for local models)
DEFAULT_NUM_CTX=32768